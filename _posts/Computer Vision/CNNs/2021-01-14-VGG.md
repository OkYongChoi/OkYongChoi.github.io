---
title: "VGG"
toc: true
categories:
  - Computer Vision
tags:
  - image classification
  - imgae localization
  - 
---

# Very Deep Convolutional Networks for Large-Scale Image Recognition, Karen Simonyan, Andrew Zisserman (VGGNet)

VGG Net is a model that won 2nd place in Classification and 1st place in Localization in ImageNet competition in 2014. The first place in classification is Google's GoogLeNet, and the Inception model from this model is still being discussed a lot. Although VGGNet lags slightly behind GoogLeNet in performance, because of its easy-to-use structure and good performance, VGGNet became more popular than the more complex GoogLeNet that won the competition. VGG stands for the Visual Geometry Group, which is the lab of the Oxford University led by Prof. Andrew Zisserman. 

From a historical point of view, starting with the VGGNet model, the depth of the network has dramatically increased. The 2012 and 2013 winning models consisted of eight layers. On the other hand, VGGNet (VGG19) in 2014 was composed of 19 layers, and GoogLeNet was composed of 22 layers. And by 2015, ResNet consisting of 152 layers was proposed. The performance improved as the network deepened. 

Here, VGGNet refers to a model consisting of 16 or 19 layers (called VGG16 and VGG19). It is different from the VGG-F, VGG-M, and VGG-S. The models are similar to AlexNet with 8 layers. However, it was not implemented in a parallel structure like AlexNet.

## Disadvantages of increasing the depth of the network?
1. As the network grows, the number of parameters increases, which increases the possibility of falling into overfitting. This becomes a more serious problem, especially when the amount of data to be used for training is limited.

2. As the number of parameters increases, the amount of computation increases. For example, when the number of filters increases, the amount of computation increases with a square.

3. As the results of ZFNet show, if the kernel of the filter is focused on a specific group due to incorrect learning, the optimal result may not be obtained even though the taste size is increased at most.



The VGG research team confirmed through experiments that Local Response Normalization (LRN) used in AlexNet and VGG-F, VGG-M, and VGG-S had no effect on performance improvement by comparing the performance of the A structure and the A-LRN structure. . Therefore, it is stated in the paper that LRN is not applied to the deeper B, C, D, and E structures. They also observed that the classification error decreased as the depth increased to 11, 13, 16, and 19 layers. In other words, the deeper the depth, the better the performance.

Before looking deeply into the structure of VGGNet, there are some things that we need to grasp first. That is, convolution with a 3 x 3 filter twice and convolution with a 5 x 5 filter once yields a feature map of the same size as a result. Convolution with a 3 x 3 filter three times corresponds to convolution with a 7 x 7 filter once.

So what's the benefit of doing three convolutions with a 3 x 3 filter over one convolution with a 5 x 5 filter? First, it is the difference in the number of weights or parameters. If there are 3 3 x 3 filters, it has a total of 27 weights. On the other hand, the 7 x 7 filter has 49 weights. In CNN, all weights require training, so the smaller the weight, the smaller the number of things to be trained. Therefore, the learning speed is accelerated. At the same time, the feature becomes more and more useful as the number of layers increases, further increasing the nonlinearity in the feature.

Like AlexNet or ZFNet, VGGNet takes 3 x 224 x 224 images as input and has a simple structure with max-pooling layer following one or more convolutional layers.
![](https://production-media.paperswithcode.com/methods/vgg_7mT4DML.png "VGGNet")

![CNN Architectures â€” VGGNet. Small filters, deeper network. | by Gary(Chang,  Chih-Chun) | Deep Learning#g | Medium](https://miro.medium.com/max/1016/1*ZKtkYKJTT76-y_GtbFDhbg.jpeg)
[VGGNet](https://ethereon.github.io/netscope/#/preset/vgg-16) 

One of the biggest drawbacks of VGGNet is that it has too many parameters, as GoogLeNet author Szegedy criticized. While GoogLeNet had 5 M parameters, VGGNet has a huge number of parameters: 138M in D-structure (VGG-16), 144M in E-structure (VGG-19), and 133M in the simplest A-structure. The reason is that VGGNet has 3 fully-connected layers at the end like AlexNet, and the number of parameters is about 122M in this part alone. For reference, Googlenet does not have a fully-connected layer. The reason why VGGNet has this structure is that it follows the structure of AlexNet to some extent and mainly examines only the depth aspect of the network, so it is estimated that the concerns about the number of parameters are relatively insufficient.

